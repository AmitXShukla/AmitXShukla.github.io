{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2P (Procure to Pay) Data Analysis & Visualization, Machine Learning Predictive Analytics using Julia Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **Part - 3** of 3 ERP Data analysis notebooks.\n",
    "- Part 1 - General Ledger, Data Science Basics\n",
    "- Part 2 - General Ledger Data Analysis & Visualization\n",
    "- Part 3 - P2P (Procure to Pay) Data Analysis & Visualization\n",
    "\n",
    "**Related blogs:**\n",
    "    \n",
    "- [Web-scrapping, Web automation using Julia Language](https://amit-shukla.medium.com/web-scrapping-web-automation-using-julia-language-2c473db84fbc)\n",
    "- Working with ODBC, ORM, XML, JSON, PDF, TXT, CSV, XLS\n",
    "- Working with PDF documents, Image Scanner, OCR Reader\n",
    "\n",
    "**Target Audience:** This notebook, is meant for ERP consultants, IT Developers, Finance, Supply chain, HR & CRM managers, executive leaders or anyone curious to implement data science concepts in ERP space.\n",
    "\n",
    "+ **Author:** Amit Shukla\n",
    "+ **Contact:** info@elishconsulting.com\n",
    "\n",
    "In part 1, 2 of 3 series notebooks, we covered basics & details of ERP Data Finance model and learned basics of DataFrames.jl package and looked into perform detail ERP Data Analysis with visualizations.\n",
    "\n",
    "\n",
    "In this part 3 notebook, we will continue to analyze Supply Chain data in aspects of Procure to Pay P2P, often referred as Buy to Pay B2P.\n",
    "\n",
    "## adding Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
      " \u001b[90m [336ed68f] \u001b[39mCSV v0.10.3\n",
      " \u001b[90m [54eefc05] \u001b[39mCascadia v1.0.1\n",
      " \u001b[90m [324d7699] \u001b[39mCategoricalArrays v0.10.5\n",
      " \u001b[90m [8f4d0f93] \u001b[39mConda v1.7.0\n",
      " \u001b[90m [a93c6f00] \u001b[39mDataFrames v1.3.2\n",
      " \u001b[90m [31c24e10] \u001b[39mDistributions v0.25.53\n",
      " \u001b[90m [e30172f5] \u001b[39mDocumenter v0.27.15\n",
      " \u001b[90m [8f5d6c58] \u001b[39mEzXML v1.1.0\n",
      " \u001b[90m [708ec375] \u001b[39mGumbo v0.8.0\n",
      " \u001b[90m [cd3eb016] \u001b[39mHTTP v0.9.17\n",
      " \u001b[90m [7073ff75] \u001b[39mIJulia v1.23.2\n",
      " \u001b[90m [c601a237] \u001b[39mInteract v0.10.4\n",
      " \u001b[90m [0f8b85d8] \u001b[39mJSON3 v1.9.4\n",
      " \u001b[90m [b9914132] \u001b[39mJSONTables v1.0.3\n",
      " \u001b[90m [4d0d745f] \u001b[39mPDFIO v0.1.13\n",
      " \u001b[90m [c3e4b0f8] \u001b[39mPluto v0.18.4\n",
      " \u001b[90m [2dfb63ee] \u001b[39mPooledArrays v1.4.0\n",
      " \u001b[90m [438e738f] \u001b[39mPyCall v1.93.1\n",
      " \u001b[90m [88034a9c] \u001b[39mStringDistances v0.11.2\n",
      " \u001b[90m [a2db99b7] \u001b[39mTextAnalysis v0.7.3\n",
      " \u001b[90m [05625dda] \u001b[39mWebDriver v0.1.2\n",
      " \u001b[90m [0f1e0344] \u001b[39mWebIO v0.8.17\n",
      " \u001b[90m [fdbf4ff8] \u001b[39mXLSX v0.7.9\n",
      " \u001b[90m [ade2ca70] \u001b[39mDates\n",
      " \u001b[90m [8bb1440f] \u001b[39mDelimitedFiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FillArrays ──── v0.13.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsFuns ───── v0.9.18\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Distributions ─ v0.25.53\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
      " \u001b[90m [31c24e10] \u001b[39m\u001b[92m+ Distributions v0.25.53\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Manifest.toml`\n",
      " \u001b[90m [b429d917] \u001b[39m\u001b[92m+ DensityInterface v0.4.0\u001b[39m\n",
      " \u001b[90m [31c24e10] \u001b[39m\u001b[92m+ Distributions v0.25.53\u001b[39m\n",
      " \u001b[90m [1a297f60] \u001b[39m\u001b[92m+ FillArrays v0.13.2\u001b[39m\n",
      " \u001b[90m [90014a1f] \u001b[39m\u001b[92m+ PDMats v0.11.7\u001b[39m\n",
      " \u001b[90m [1fd47b50] \u001b[39m\u001b[92m+ QuadGK v2.4.2\u001b[39m\n",
      " \u001b[90m [79098fc4] \u001b[39m\u001b[92m+ Rmath v0.7.0\u001b[39m\n",
      " \u001b[90m [276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v2.1.4\u001b[39m\n",
      " \u001b[90m [4c63d2b9] \u001b[39m\u001b[92m+ StatsFuns v0.9.18\u001b[39m\n",
      " \u001b[90m [efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.5+0\u001b[39m\n",
      " \u001b[90m [f50d1b31] \u001b[39m\u001b[92m+ Rmath_jll v0.3.0+0\u001b[39m\n",
      " \u001b[90m [4607b0f0] \u001b[39m\u001b[92m+ SuiteSparse\u001b[39m\n",
      " \u001b[90m [05823500] \u001b[39m\u001b[92m+ OpenLibm_jll\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFillArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mDistributions\n",
      "  3 dependencies successfully precompiled in 12 seconds (127 already precompiled)\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m WebIO → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/c9529be473e97fa0b3b2642cdafcd0896b4c9494/build.log`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Dates\")\n",
    "Pkg.add(\"CategoricalArrays\")\n",
    "Pkg.add(\"Interact\")\n",
    "Pkg.add(\"WebIO\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"XLSX\")\n",
    "Pkg.add(\"DelimitedFiles\")\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.build(\"WebIO\")\n",
    "Pkg.status();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.webio.node+json": {
       "children": [],
       "instanceArgs": {
        "namespace": "html",
        "tag": "div"
       },
       "nodeType": "DOM",
       "props": {},
       "type": "node"
      },
      "text/html": [
       "<div style=\"padding: 1em; background-color: #f8d6da; border: 1px solid #f5c6cb; font-weight: bold;\">\n",
       "<p>The WebIO Jupyter extension was not detected. See the\n",
       "<a href=\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\" target=\"_blank\">\n",
       "    WebIO Jupyter integration documentation\n",
       "</a>\n",
       "for more information.\n",
       "</div>\n"
      ],
      "text/plain": [
       "WebIO._IJuliaInit()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using DataFrames, Dates, Interact, CategoricalArrays, WebIO, CSV, XLSX, DelimitedFiles, Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*rest of this blog, I will assume, you have added all packages and imported in current namespace/notebook scope.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Supply Chain Data Model\n",
    "We already covered DataFrames and ERP Finance data model in Part 1 & Part 2 notebooks, in below section, let's recreate all Supply Chain DataFrames to continue advance analytics and visualization.\n",
    "\n",
    "#### Dimensions\n",
    "\n",
    "- Item master, Item Attribs, Item Costing\n",
    "\n",
    "    **UNSPSC:**  The United Nations Standard Products and Services Code® (UNSPSC®) is a global classification system of products and services.\n",
    "                These codes are used to classify products and services.\n",
    "    \n",
    "    **GUDID:** The Global Unique Device Identification Database (GUDID) is a database administered by the FDA that will serve as a reference catalog for every device with a unique device identifier (UDI).\n",
    "\n",
    "    **GTIN:** Global Trade Item Number (GTIN) can be used by a company to uniquely identify all of its trade items. GS1 defines trade items as products or services that are priced, ordered or invoiced at any point in the supply chain.\n",
    "\n",
    "    **GMDN:** The Global Medical Device Nomenclature (GMDN) is a comprehensive set of terms, within a structured category hierarchy, which name and group ALL medical device products including implantables, medical equipment, consumables, and diagnostic devices.\n",
    "    \n",
    "    \n",
    "- Vendor master, Vendor Attribs, Vendor Costing\n",
    "    Customer/Buyer/Procurement Officer Attribs\n",
    "    shipto, warehouse, storage & inventory locations\n",
    "\n",
    "#### Transactions\n",
    "\n",
    "-   PurchaseOrder\n",
    "-   MSR - Material Service\n",
    "-   Voucher\n",
    "-   Invoice\n",
    "-   Receipt\n",
    "-   Shipment\n",
    "-   Sales, Revenue\n",
    "-   Travel, Expense, TimeCard\n",
    "-   Accounting Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"UNSPSC.csv\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "## create SUPPLY CHAIN DATA ###\n",
    "###############################\n",
    "# Item master, Item Attribs, Item Costing ##\n",
    "#       UNSPSC, GUDID, GTIN, GMDN\n",
    "############################################\n",
    "\n",
    "##########\n",
    "# UNSPSC #\n",
    "##########\n",
    "# UNSPSC file can be downloaded from this link https://www.ungm.org/Public/UNSPSC\n",
    "xf = XLSX.readxlsx(\"sampleData/UNGM_UNSPSC_09-Apr-2022..xlsx\")\n",
    "# xf will display names of sheets and rows with data\n",
    "# let's read this data in to a DataFrame\n",
    "\n",
    "# using below command will read xlsx data into DataFrame but will not render column labels\n",
    "# df = DataFrame(XLSX.readdata(\"UNGM_UNSPSC_09-Apr-2022..xlsx\", \"UNSPSC\", \"A1:D12988\"), :auto)\n",
    "dfUNSPSC = DataFrame(XLSX.readtable(\"sampleData/UNGM_UNSPSC_09-Apr-2022..xlsx\", \"UNSPSC\")...)\n",
    "# ... operator will splat the tuple (data, column_labels) into the constructor of DataFrame\n",
    "\n",
    "# replace missing values with an integer 99999\n",
    "replace!(dfUNSPSC.\"Parent key\", missing => 99999)\n",
    "size(dfUNSPSC)\n",
    "\n",
    "# let's export this clean csv, we'll load this into database\n",
    "# CSV.write(\"UNSPSC.csv\", dfUNSPSC)\n",
    "\n",
    "# # remember to empty dataFrame after usage\n",
    "# # Julia will flush it out automatically after session,\n",
    "# # but often ERP data gets bulky during session\n",
    "# Base.summarysize(dfUNSPSC)\n",
    "# empty!(dfUNSPSC)\n",
    "# Base.summarysize(dfUNSPSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GUDID.csv\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########\n",
    "# GUDID ##\n",
    "##########\n",
    "# The complete list of GUDID Data Elements and descriptions can be found at this link.\n",
    "# https://www.fda.gov/media/120974/download\n",
    "# The complete GUDID Database (delimited version) download (250+MB)\n",
    "# https://accessgudid.nlm.nih.gov/release_files/download/AccessGUDID_Delimited_Full_Release_20220401.zip\n",
    "# let's extract all GUDID files in a folder\n",
    "# readdir(pwd())\n",
    "# readdir(\"sampleData/GUDID\")\n",
    "# since these files are in txt (delimited) format, we'll use delimited pkg\n",
    "\n",
    "########################\n",
    "## large txt files #####\n",
    "## read one at a time ##\n",
    "########################\n",
    "\n",
    "# data, header = readdlm(\"sampleData/GUDID/contacts.txt\", '|', header=true)\n",
    "# dfGUDIDcontacts = DataFrame(data, vec(header))\n",
    "\n",
    "# data, header = readdlm(\"sampleData/GUDID/identifiers.txt\", '|', header=true)\n",
    "# dfGUDIDidentifiers = DataFrame(data, vec(header))\n",
    "\n",
    "data, header = readdlm(\"sampleData/GUDID/device.txt\", '|', header=true)\n",
    "dfGUDIDdevice = DataFrame(data, vec(header))\n",
    "\n",
    "# CSV.write(\"GUDID.csv\", dfGUDIDdevice[1:1000,:])\n",
    "\n",
    "# # remember to empty dataFrame after usage\n",
    "# # Julia will flush it out automatically after session,\n",
    "# # but often ERP data gets bulky during session\n",
    "# Base.summarysize(dfGUDIDcontacts),Base.summarysize(dfGUDIDidentifiers),Base.summarysize(dfGUDIDdevice)\n",
    "# empty!(dfGUDIDcontacts)\n",
    "# empty!(dfGUDIDidentifiers)\n",
    "# empty!(dfGUDIDdevice)\n",
    "# Base.summarysize(dfGUDIDcontacts),Base.summarysize(dfGUDIDidentifiers),Base.summarysize(dfGUDIDdevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3308327, 34)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfGUDIDdevice has more than 3308327 rows,\n",
    "# let's split this in 6 mini files, \n",
    "# so that, it can be loaded into RDBMS easily\n",
    "size(dfGUDIDdevice)\n",
    "# CSV.write(\"dfGUDIDdevice_1.csv\", dfGUDIDdevice[1:500000,:])\n",
    "# CSV.write(\"dfGUDIDdevice_2.csv\", dfGUDIDdevice[500001:1000000,:])\n",
    "# CSV.write(\"dfGUDIDdevice_3.csv\", dfGUDIDdevice[1000001:1500000,:])\n",
    "# CSV.write(\"dfGUDIDdevice_4.csv\", dfGUDIDdevice[1500001:2000000,:])\n",
    "# CSV.write(\"dfGUDIDdevice_5.csv\", dfGUDIDdevice[2000001:2500000,:])\n",
    "# CSV.write(\"dfGUDIDdevice_6.csv\", dfGUDIDdevice[2500001:3308327,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GTIN.csv\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########\n",
    "# GTIN ###\n",
    "##########\n",
    "\n",
    "# xf = XLSX.readxlsx(\"SampleData/DS_GTIN_ALL.xlsx\")\n",
    "# xf will display names of sheets and rows with data\n",
    "# let's read this data in to a DataFrame\n",
    "\n",
    "# using below command will read xlsx data into DataFrame but will not render column labels\n",
    "# df = DataFrame(XLSX.readdata(\"SampleData/DS_GTIN_ALL.xlsx\", \"Worksheet\", \"A14:E143403   \"), :auto)\n",
    "dfGTIN = DataFrame(XLSX.readtable(\"sampleData/DS_GTIN_ALL.xlsx\", \"Worksheet\";first_row=14)...)\n",
    "# ... operator will splat the tuple (data, column_labels) into the constructor of DataFrame\n",
    "\n",
    "# replace missing values with an integer 99999\n",
    "# replace!(dfUNSPSC.\"Parent key\", missing => 99999)\n",
    "# size(dfUNSPSC)\n",
    "\n",
    "# let's export this clean csv, we'll load this into database\n",
    "# CSV.write(\"GTIN.csv\", dfGTIN)\n",
    "# readdir(pwd())\n",
    "\n",
    "# # remember to empty dataFrame after usage\n",
    "# # Julia will flush it out automatically after session,\n",
    "# # but often ERP data gets bulky during session\n",
    "# Base.summarysize(dfGTIN)\n",
    "# empty!(dfGTIN)\n",
    "# Base.summarysize(dfGTIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# GMDN ###\n",
    "##########\n",
    "\n",
    "## GMDN data is not available\n",
    "\n",
    "# # remember to empty dataFrame after usage\n",
    "# # Julia will flush it out automatically after session,\n",
    "# # but often ERP data gets bulky during session\n",
    "# Base.summarysize(dfGMDN)\n",
    "# empty!(dfGMDN)\n",
    "# Base.summarysize(dfGMDN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vendor Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"VENDOR.csv\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################\n",
    "# Vendor master #\n",
    "#################\n",
    "# create Vendor Master from GUDID dataset\n",
    "# show(first(dfGUDIDdevice,5), allcols=true)\n",
    "# show(first(dfGUDIDdevice[:,[:brandName, :catalogNumber, :dunsNumber, :companyName, :rx, :otc]],5), allcols=true)\n",
    "# names(dfGUDIDdevice)\n",
    "# dfVendor = unique(dfGUDIDdevice[:,[:brandName, :catalogNumber, :dunsNumber, :companyName, :rx, :otc]])\n",
    "# dfVendor = unique(dfGUDIDdevice[:,[:companyName]]) # 7574 unique vendors\n",
    "dfVendor = unique(dfGUDIDdevice[:,[:brandName, :dunsNumber, :companyName, :rx, :otc]])\n",
    "# dfVendor is a good dataset, have 216k rows for 7574 unique vendors\n",
    "\n",
    "# # remember to empty dataFrame after usage\n",
    "# # Julia will flush it out automatically after session,\n",
    "# # but often ERP data gets bulky during session\n",
    "# Base.summarysize(dfVendor)\n",
    "# empty!(dfVendor)\n",
    "# Base.summarysize(dfVendor)\n",
    "\n",
    "# CSV.write(\"VENDOR.csv\", dfVendor[1:1000,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LOCATION_MASTER.csv\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, header = readdlm(\"sampleData/uscities.csv\", ',', header=true)\n",
    "dfLocation = DataFrame(data, vec(header))\n",
    "\n",
    "# # remember to empty dataFrame after usage\n",
    "# # Julia will flush it out automatically after session,\n",
    "# # but often ERP data gets bulky during session\n",
    "# Base.summarysize(dfLocation)\n",
    "# empty!(dfLocation)\n",
    "# Base.summarysize(dfLocation)\n",
    "\n",
    "# CSV.write(\"LOCATION_MASTER.csv\", dfLocation[1:1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{String}:\n",
       " \"contacts.txt\"\n",
       " \"device.txt\"\n",
       " \"deviceSizes.txt\"\n",
       " \"environmentalConditions.txt\"\n",
       " \"gmdnTerms.txt\"\n",
       " \"identifiers.txt\"\n",
       " \"premarketSubmissions.txt\"\n",
       " \"productCodes.txt\"\n",
       " \"sterilizationMethodTypes.txt\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readdir(\"sampleData/GUDID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ORG_MASTER.csv\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOrgMaster = DataFrame(\n",
    "    ENTITY=repeat([\"HeadOffice\"], inner=8),\n",
    "    GROUP=repeat([\"Operations\"], inner=8),\n",
    "    DEPARTMENT=[\"Procurement\",\"Procurement\",\"Procurement\",\"Procurement\",\"Procurement\",\"HR\",\"HR\",\"MFG\"],\n",
    "    UNIT=[\"Sourcing\",\"Sourcing\",\"Maintenance\",\"Support\",\"Services\",\"Helpdesk\",\"ServiceCall\",\"IT\"])\n",
    "\n",
    "    # CSV.write(\"ORG_MASTER.csv\", dfOrgMaster[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## creating complete Supply Chain Data Model DataFrames\n",
    "now since we created Supply chain attribute / chartfields/dimensions\n",
    "\n",
    "- item master\n",
    "- vendor master\n",
    "- location master\n",
    "- org Hierarchy\n",
    "\n",
    "using above chartfields, let's create following Supply Chain Transactions\n",
    "\n",
    "-   MSR - Material Service request\n",
    "-   PurchaseOrder\n",
    "-   Voucher\n",
    "-   Invoice\n",
    "-   Receipt\n",
    "-   Shipment\n",
    "-   Sales, Revenue\n",
    "-   Travel, Expense, TimeCard\n",
    "-   Accounting Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSR - Material Service request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MSR.csv\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 1000 # number of rows, scale as needed\n",
    "\n",
    "dfMSR = DataFrame(\n",
    "    UNIT = rand(dfOrgMaster.UNIT, sampleSize),\n",
    "    MSR_DATE=rand(collect(Date(2020,1,1):Day(1):Date(2022,5,1)), sampleSize),\n",
    "    FROM_UNIT = rand(dfOrgMaster.UNIT, sampleSize),\n",
    "    TO_UNIT = rand(dfOrgMaster.UNIT, sampleSize),\n",
    "    GUDID = rand(dfGUDIDdevice.PrimaryDI, sampleSize),\n",
    "    QTY = rand(dfOrgMaster.UNIT, sampleSize));\n",
    "first(dfMSR, 5)\n",
    "\n",
    "    # CSV.write(\"MSR.csv\", dfMSR[1:1000,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purchase Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5×6 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m UNIT        \u001b[0m\u001b[1m PO_DATE    \u001b[0m\u001b[1m VENDOR                            \u001b[0m\u001b[1m GUDID          \u001b[0m\u001b[1m QTY   \u001b[0m\u001b[1m UNIT_PRICE \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String      \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m Any                               \u001b[0m\u001b[90m Any            \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64    \u001b[0m\n",
      "─────┼───────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │ Sourcing     2021-03-12  CAREDX, INC.                       191072148612       42     99.4394\n",
      "   2 │ Services     2021-11-15  SUTTER MEDICAL TECHNOLOGIES USA,…  M7256008545       106    101.331\n",
      "   3 │ ServiceCall  2020-09-16  NEWMARKET BIOMEDICAL LIMITED       10884521795143    146     99.0341\n",
      "   4 │ Support      2022-02-08  WATERS MEDICAL SYSTEMS, LLC        5415067023377     131     97.6662\n",
      "   5 │ Sourcing     2020-05-17  ULTHERA, INC.                      385640029568      142     96.7298"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"PO.csv\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 1000 # number of rows, scale as needed\n",
    "\n",
    "dfPO = DataFrame(\n",
    "    UNIT = rand(dfOrgMaster.UNIT, sampleSize),\n",
    "    PO_DATE=rand(collect(Date(2020,1,1):Day(1):Date(2022,5,1)), sampleSize),\n",
    "    VENDOR=rand(unique(dfVendor.companyName), sampleSize),\n",
    "    GUDID = rand(dfGUDIDdevice.PrimaryDI, sampleSize),\n",
    "    QTY = rand(1:150, sampleSize),\n",
    "    UNIT_PRICE = rand(Normal(100, 2), sampleSize)\n",
    "    );\n",
    "show(first(dfPO, 5),allcols=true)\n",
    "\n",
    "# CSV.write(\"PO.csv\", dfPO[1:1000,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voucher Invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5×8 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m UNIT        \u001b[0m\u001b[1m VCHR_DATE  \u001b[0m\u001b[1m STATUS    \u001b[0m\u001b[1m VENDOR_INVOICE_NUM \u001b[0m\u001b[1m VENDOR                         \u001b[0m\u001b[1m GUDID         \u001b[0m\u001b[1m QTY   \u001b[0m\u001b[1m UNIT_PRICE \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String      \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m String    \u001b[0m\u001b[90m Int64              \u001b[0m\u001b[90m Any                            \u001b[0m\u001b[90m Any           \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64    \u001b[0m\n",
      "─────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │ Helpdesk     2021-08-17  Open                   769145  GERMAINE LABORATORIES, INC      814033020559      31    102.394\n",
      "   2 │ Maintenance  2020-03-18  Cancelled             6922830  OSADA ELECTRIC CO.,LTD.         814978020546      50    101.569\n",
      "   3 │ Support      2022-02-24  Cancelled             2343017  Hangzhou AGS MedTech Co., Ltd.  8056640016767    146     99.7956\n",
      "   4 │ Services     2021-08-02  Closed                1790351  BIOLASE, INC.                   877466000451      84    101.251\n",
      "   5 │ IT           2021-01-28  Exception             8866228  DETAX GmbH & Co. KG             4019702332513    140     97.9296"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"VOUCHER.csv\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 1000 # number of rows, scale as needed\n",
    "\n",
    "dfVCHR = DataFrame(\n",
    "    UNIT = rand(dfOrgMaster.UNIT, sampleSize),\n",
    "    VCHR_DATE=rand(collect(Date(2020,1,1):Day(1):Date(2022,5,1)), sampleSize),\n",
    "    STATUS=rand([\"Closed\",\"Paid\",\"Open\",\"Cancelled\",\"Exception\"], sampleSize),\n",
    "    VENDOR_INVOICE_NUM = rand(10001:9999999, sampleSize),\n",
    "    VENDOR=rand(unique(dfVendor.companyName), sampleSize),\n",
    "    GUDID = rand(dfGUDIDdevice.PrimaryDI, sampleSize),\n",
    "    QTY = rand(1:150, sampleSize),\n",
    "    UNIT_PRICE = rand(Normal(100, 2), sampleSize)\n",
    "    );\n",
    "show(first(dfVCHR, 5),allcols=true)\n",
    "\n",
    "# CSV.write(\"VOUCHER.csv\", dfVCHR[1:1000,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5×8 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m UNIT     \u001b[0m\u001b[1m SALES_DATE \u001b[0m\u001b[1m STATUS    \u001b[0m\u001b[1m SALES_RECEIPT_NUM \u001b[0m\u001b[1m CUSTOMER                          \u001b[0m\u001b[1m GUDID         \u001b[0m\u001b[1m QTY   \u001b[0m\u001b[1m UNIT_PRICE \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String   \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m String    \u001b[0m\u001b[90m Int64             \u001b[0m\u001b[90m Any                               \u001b[0m\u001b[90m Any           \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64    \u001b[0m\n",
      "─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │ Sourcing  2020-02-05  Cancelled            9590264  Siemens Shanghai Medical Equipme…  8806378323473     83    100.088\n",
      "   2 │ Support   2021-07-12  Sold                 8926812  AB Ardent                          3700780603770     23    104.813\n",
      "   3 │ Services  2021-05-23  Hold                 4004679  Ambra Health                       887517046635      72    100.262\n",
      "   4 │ Helpdesk  2022-02-20  Pending              1459425  SHIFENG MEDICAL TECHNOLOGY CO.，…  4038653934966    139    100.445\n",
      "   5 │ IT        2021-01-21  Cancelled            7805658  VALES & HILLS BIOMEDICAL TECH. L…  5055455506763     74     99.1025"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"SALES.csv\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 1000 # number of rows, scale as needed\n",
    "\n",
    "dfREVENUE = DataFrame(\n",
    "    UNIT = rand(dfOrgMaster.UNIT, sampleSize),\n",
    "    SALES_DATE=rand(collect(Date(2020,1,1):Day(1):Date(2022,5,1)), sampleSize),\n",
    "    STATUS=rand([\"Sold\",\"Pending\",\"Hold\",\"Cancelled\",\"Exception\"], sampleSize),\n",
    "    SALES_RECEIPT_NUM = rand(10001:9999999, sampleSize),\n",
    "    CUSTOMER=rand(unique(dfVendor.companyName), sampleSize),\n",
    "    GUDID = rand(dfGUDIDdevice.PrimaryDI, sampleSize),\n",
    "    QTY = rand(1:150, sampleSize),\n",
    "    UNIT_PRICE = rand(Normal(100, 2), sampleSize)\n",
    "    );\n",
    "show(first(dfREVENUE, 5),allcols=true)\n",
    "\n",
    "# CSV.write(\"SALES.csv\", dfREVENUE[1:1000,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHIPMENT, RECEIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5×8 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m UNIT        \u001b[0m\u001b[1m SHIP_DATE  \u001b[0m\u001b[1m STATUS    \u001b[0m\u001b[1m SHIPMENT_NUM \u001b[0m\u001b[1m CUSTOMER                          \u001b[0m\u001b[1m GUDID          \u001b[0m\u001b[1m QTY   \u001b[0m\u001b[1m UNIT_PRICE \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String      \u001b[0m\u001b[90m Date       \u001b[0m\u001b[90m String    \u001b[0m\u001b[90m Int64        \u001b[0m\u001b[90m Any                               \u001b[0m\u001b[90m Any            \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64    \u001b[0m\n",
      "─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │ Helpdesk     2020-01-03  Shippped        6110428  NIMBIC SYSTEMS, INC.               10809160251607     20     95.9247\n",
      "   2 │ Sourcing     2020-01-11  Cancelled       4638687  Scican Ltd                         30634303020123    130     99.9792\n",
      "   3 │ ServiceCall  2020-09-25  Cancelled       9330541  W.H.P.M. INC.                      887517888754       68    100.744\n",
      "   4 │ Helpdesk     2020-12-03  Exception       6892474  DORAN SCALES, INC.                 10381780091813     37    102.929\n",
      "   5 │ ServiceCall  2020-03-12  Shippped        8681342  Beijing Anchorfree Technology Co…  5030267066230     130     99.036"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"SHIPRECEIPT.csv\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 1000 # number of rows, scale as needed\n",
    "\n",
    "dfSHIPRECEIPT = DataFrame(\n",
    "    UNIT = rand(dfOrgMaster.UNIT, sampleSize),\n",
    "    SHIP_DATE=rand(collect(Date(2020,1,1):Day(1):Date(2022,5,1)), sampleSize),\n",
    "    STATUS=rand([\"Shippped\",\"Returned\",\"In process\",\"Cancelled\",\"Exception\"], sampleSize),\n",
    "    SHIPMENT_NUM = rand(10001:9999999, sampleSize),\n",
    "    CUSTOMER=rand(unique(dfVendor.companyName), sampleSize),\n",
    "    GUDID = rand(dfGUDIDdevice.PrimaryDI, sampleSize),\n",
    "    QTY = rand(1:150, sampleSize),\n",
    "    UNIT_PRICE = rand(Normal(100, 2), sampleSize)\n",
    "    );\n",
    "show(first(dfSHIPRECEIPT, 5),allcols=true)\n",
    "\n",
    "# CSV.write(\"SHIPRECEIPT.csv\", dfSHIPRECEIPT[1:1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "cc4906c3096a4cdf8008983365b2ebab",
   "lastKernelId": "222a4d4f-0ee5-4cda-9ee5-db54f3ec3e98"
  },
  "kernelspec": {
   "display_name": "Julia (4 threads) 1.7.0",
   "language": "julia",
   "name": "julia-(4-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
