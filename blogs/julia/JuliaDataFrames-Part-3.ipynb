{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2P (Procure to Pay) Data Analysis & Visualization, Machine Learning Predictive Analytics using Julia Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **Part - 3** of 3 ERP Data analysis notebooks.\n",
    "- Part 1 - General Ledger, Data Science Basics\n",
    "- Part 2 - General Ledger Data Analysis & Visualization\n",
    "- Part 3 - P2P (Procure to Pay) Data Analysis & Visualization\n",
    "\n",
    "**Related blogs:**\n",
    "    \n",
    "- [Web-scrapping, Web automation using Julia Language](https://amit-shukla.medium.com/web-scrapping-web-automation-using-julia-language-2c473db84fbc)\n",
    "- Working with ODBC, ORM, XML, JSON, PDF, TXT, CSV, XLS\n",
    "- Working with PDF documents, Image Scanner, OCR Reader\n",
    "\n",
    "**Target Audience:** This notebook, is meant for ERP consultants, IT Developers, Finance, Supply chain, HR & CRM managers, executive leaders or anyone curious to implement data science concepts in ERP space.\n",
    "\n",
    "+ **Author:** Amit Shukla\n",
    "+ **Contact:** info@elishconsulting.com\n",
    "\n",
    "In part 1, 2 of 3 series notebooks, we covered basics & details of ERP Data Finance model and learned basics of DataFrames.jl package and looked into perform detail ERP Data Analysis with visualizations.\n",
    "\n",
    "\n",
    "In this part 3 notebook, we will continue to analyze Supply Chain data in aspects of Procure to Pay P2P, often referred as Buy to Pay B2P.\n",
    "\n",
    "## adding Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.webio.node+json": {
       "children": [],
       "instanceArgs": {
        "namespace": "html",
        "tag": "div"
       },
       "nodeType": "DOM",
       "props": {},
       "type": "node"
      },
      "text/html": [
       "<div style=\"padding: 1em; background-color: #f8d6da; border: 1px solid #f5c6cb; font-weight: bold;\">\n",
       "<p>The WebIO Jupyter extension was not detected. See the\n",
       "<a href=\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\" target=\"_blank\">\n",
       "    WebIO Jupyter integration documentation\n",
       "</a>\n",
       "for more information.\n",
       "</div>\n"
      ],
      "text/plain": [
       "WebIO._IJuliaInit()"
      ]
     },
     "metadata": {
      "application/vnd.webio.node+json": {
       "kernelId": "ff6555df-dff2-4490-9640-d7a8135f90b6"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
      " \u001b[90m [336ed68f] \u001b[39mCSV v0.10.3\n",
      " \u001b[90m [54eefc05] \u001b[39mCascadia v1.0.1\n",
      " \u001b[90m [324d7699] \u001b[39mCategoricalArrays v0.10.5\n",
      " \u001b[90m [8f4d0f93] \u001b[39mConda v1.7.0\n",
      " \u001b[90m [a93c6f00] \u001b[39mDataFrames v1.3.2\n",
      " \u001b[90m [e30172f5] \u001b[39mDocumenter v0.27.15\n",
      " \u001b[90m [8f5d6c58] \u001b[39mEzXML v1.1.0\n",
      " \u001b[90m [708ec375] \u001b[39mGumbo v0.8.0\n",
      " \u001b[90m [cd3eb016] \u001b[39mHTTP v0.9.17\n",
      " \u001b[90m [7073ff75] \u001b[39mIJulia v1.23.2\n",
      " \u001b[90m [c601a237] \u001b[39mInteract v0.10.4\n",
      " \u001b[90m [0f8b85d8] \u001b[39mJSON3 v1.9.4\n",
      " \u001b[90m [b9914132] \u001b[39mJSONTables v1.0.3\n",
      " \u001b[90m [4d0d745f] \u001b[39mPDFIO v0.1.13\n",
      " \u001b[90m [c3e4b0f8] \u001b[39mPluto v0.18.4\n",
      " \u001b[90m [2dfb63ee] \u001b[39mPooledArrays v1.4.0\n",
      " \u001b[90m [438e738f] \u001b[39mPyCall v1.93.1\n",
      " \u001b[90m [88034a9c] \u001b[39mStringDistances v0.11.2\n",
      " \u001b[90m [a2db99b7] \u001b[39mTextAnalysis v0.7.3\n",
      " \u001b[90m [05625dda] \u001b[39mWebDriver v0.1.2\n",
      " \u001b[90m [0f1e0344] \u001b[39mWebIO v0.8.17\n",
      " \u001b[90m [ade2ca70] \u001b[39mDates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m WebIO → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/c9529be473e97fa0b3b2642cdafcd0896b4c9494/build.log`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Dates\")\n",
    "Pkg.add(\"CategoricalArrays\")\n",
    "Pkg.add(\"Interact\")\n",
    "Pkg.add(\"WebIO\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.build(\"WebIO\")\n",
    "using DataFrames, Dates, Interact, CategoricalArrays, WebIO, CSV\n",
    "Pkg.status();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*rest of this blog, I will assume, you have added all packages and imported in current namespace/notebook scope.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Supply Chain Data Model\n",
    "We already covered DataFrames and ERP Finance data model in Part 1 & Part 2 notebooks, in below section, let's recreate all Supply Chain DataFrames to continue advance analytics and visualization.\n",
    "\n",
    "**Dimensions**\n",
    "\n",
    "    Item master, Item Attribs, Item Costing\n",
    "        UNSPSC** The United Nations Standard Products and Services Code® (UNSPSC®) is a global classification system of products and services.\n",
    "\n",
    "These codes are used to classify products and services, GUDID, GTIN, GMDN\n",
    "    Vendor master, Vendor Attribs, Vendor Costing\n",
    "    Customer/Buyer/Procurement Officer Attribs\n",
    "    shipto, warehouse, storage & inventory locations\n",
    "\n",
    "**Transactions**\n",
    "\n",
    "    Sales, Revenue\n",
    "    PurchaseOrder\n",
    "    MSR - Material Service\n",
    "    Voucher\n",
    "    Invoice\n",
    "    Receipt\n",
    "    Shipment\n",
    "    Travel, Expense, TimeCard\n",
    "    Accounting Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"df_ledger_size after transformation is: \", (2800000, 30))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "## create SUPPLY CHAIN DATA ###\n",
    "###############################\n",
    "# Item master, Item Attribs, Item Costing\n",
    "#       UNSPSC, GUDID, GTIN, GMDN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## creating complete Supply Chain Data Model DataFrames\n",
    "now since we got a handle of dataframe basics, let's create other chartfields/dimensions and create a complete Supply Chain DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"df_ledger_size after transformation is: \", (2800000, 30))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## THIS IS BACKUP ##\n",
    "###############################\n",
    "## create SUPPLY CHAIN DATA ###\n",
    "###############################\n",
    "# Item master, Item Attribs, Item Costing\n",
    "#       UNSPSC, GUDID, GTIN, GMDN\n",
    "# vendor master, Vendor Attribs, Vendor Costing\n",
    "# Item master, Item Attribs, Item Costing\n",
    "# Customer/Buyer/Procurement Officer Attribs\n",
    "# shipto, warehouse, storage & inventory locations\n",
    "###############################\n",
    "## TXNs #######################\n",
    "###############################\n",
    "# SALES master\n",
    "# PurchaseOrder master\n",
    "# MSR - Material Service Request\n",
    "# Voucher master\n",
    "# Invoice master\n",
    "# Receipt master\n",
    "# Shipment master\n",
    "# travel, expense, time cards\n",
    "# accounting lines\n",
    "###############################\n",
    "\n",
    "vendors = DataFrame(\n",
    "    ENTITY = \"Apple Inc.\",\n",
    "    AS_OF_DATE=Date(\"1900-01-01\", dateformat\"y-m-d\"),\n",
    "    ID = 11000:1000:45000,\n",
    "    CLASSIFICATION=repeat([\n",
    "        \"OPERATING_EXPENSES\",\"NON-OPERATING_EXPENSES\", \"ASSETS\",\"LIABILITIES\",\"NET_WORTH\",\"STATISTICS\",\"REVENUE\"\n",
    "                ], inner=5),\n",
    "    CATEGORY=[\n",
    "        \"Travel\",\"Payroll\",\"non-Payroll\",\"Allowance\",\"Cash\",\n",
    "        \"Facility\",\"Supply\",\"Services\",\"Investment\",\"Misc.\",\n",
    "        \"Depreciation\",\"Gain\",\"Service\",\"Retired\",\"Fault.\",\n",
    "        \"Receipt\",\"Accrual\",\"Return\",\"Credit\",\"ROI\",\n",
    "        \"Cash\",\"Funds\",\"Invest\",\"Transfer\",\"Roll-over\",\n",
    "        \"FTE\",\"Members\",\"Non_Members\",\"Temp\",\"Contractors\",\n",
    "        \"Sales\",\"Merchant\",\"Service\",\"Consulting\",\"Subscriptions\"],\n",
    "    STATUS=\"A\",\n",
    "    DESCR=repeat([\n",
    "    \"operating expenses\",\"non-operating expenses\",\"assets\",\"liability\",\"net-worth\",\"stats\",\"revenue\"], inner=5),\n",
    "    ACCOUNT_TYPE=repeat([\"E\",\"E\",\"A\",\"L\",\"N\",\"S\",\"R\"],inner=5));\n",
    "\n",
    "# DEPARTMENT Chartfield\n",
    "deptDF = DataFrame(\n",
    "    AS_OF_DATE=Date(\"2000-01-01\", dateformat\"y-m-d\"), \n",
    "    ID = 1100:100:1500,\n",
    "    CLASSIFICATION=[\"SALES\",\"HR\", \"IT\",\"BUSINESS\",\"OTHERS\"],\n",
    "    CATEGORY=[\"sales\",\"human_resource\",\"IT_Staff\",\"business\",\"others\"],\n",
    "    STATUS=\"A\",\n",
    "    DESCR=[\n",
    "    \"Sales & Marketing\",\"Human Resource\",\"Infomration Technology\",\"Business leaders\",\"other temp\"\n",
    "        ],\n",
    "    DEPT_TYPE=[\"S\",\"H\",\"I\",\"B\",\"O\"]);\n",
    "\n",
    "# LOCATION Chartfield\n",
    "locationDF = DataFrame(\n",
    "    AS_OF_DATE=Date(\"2000-01-01\", dateformat\"y-m-d\"), \n",
    "    ID = 11:1:22,\n",
    "    CLASSIFICATION=repeat([\n",
    "        \"Region A\",\"Region B\", \"Region C\"], inner=4),\n",
    "    CATEGORY=repeat([\n",
    "        \"Region A\",\"Region B\", \"Region C\"], inner=4),\n",
    "    STATUS=\"A\",\n",
    "    DESCR=[\n",
    "\"Boston\",\"New York\",\"Philadelphia\",\"Cleveland\",\"Richmond\",\n",
    "\"Atlanta\",\"Chicago\",\"St. Louis\",\"Minneapolis\",\"Kansas City\",\n",
    "\"Dallas\",\"San Francisco\"],\n",
    "    LOC_TYPE=\"Physical\");\n",
    "\n",
    "# creating Ledger\n",
    "ledgerDF = DataFrame(\n",
    "            LEDGER = String[], FISCAL_YEAR = Int[], PERIOD = Int[], ORGID = String[],\n",
    "            OPER_UNIT = String[], ACCOUNT = Int[], DEPT = Int[], LOCATION = Int[],\n",
    "            POSTED_TOTAL = Float64[]\n",
    "            );\n",
    "\n",
    "# create 2020 Period 1-12 Actuals Ledger \n",
    "l = \"Actuals\";\n",
    "fy = 2020;\n",
    "for p = 1:12\n",
    "    for i = 1:10^5\n",
    "        push!(ledgerDF, (l, fy, p, \"ABC Inc.\", rand(locationDF.CATEGORY),\n",
    "            rand(accountsDF.ID), rand(deptDF.ID), rand(locationDF.ID), rand()*10^8))\n",
    "    end\n",
    "end\n",
    "\n",
    "# create 2021 Period 1-4 Actuals Ledger \n",
    "l = \"Actuals\";\n",
    "fy = 2021;\n",
    "for p = 1:4\n",
    "    for i = 1:10^5\n",
    "        push!(ledgerDF, (l, fy, p, \"ABC Inc.\", rand(locationDF.CATEGORY),\n",
    "            rand(accountsDF.ID), rand(deptDF.ID), rand(locationDF.ID), rand()*10^8))\n",
    "    end\n",
    "end\n",
    "\n",
    "# create 2021 Period 1-4 Budget Ledger \n",
    "l = \"Budget\";\n",
    "fy = 2021;\n",
    "for p = 1:12\n",
    "    for i = 1:10^5\n",
    "        push!(ledgerDF, (l, fy, p, \"ABC Inc.\", rand(locationDF.CATEGORY),\n",
    "            rand(accountsDF.ID), rand(deptDF.ID), rand(locationDF.ID), rand()*10^8))\n",
    "    end\n",
    "end\n",
    "\n",
    "# here is ~3 million rows ledger dataframe\n",
    "size(ledgerDF)\n",
    "\n",
    "# rename dimensions columns for innerjoin\n",
    "df_accounts = rename(accountsDF, :ID => :ACCOUNTS_ID, :CLASSIFICATION => :ACCOUNTS_CLASSIFICATION, \n",
    "    :CATEGORY => :ACCOUNTS_CATEGORY, :DESCR => :ACCOUNTS_DESCR);\n",
    "df_dept = rename(deptDF, :ID => :DEPT_ID, :CLASSIFICATION => :DEPT_CLASSIFICATION, \n",
    "    :CATEGORY => :DEPT_CATEGORY, :DESCR => :DEPT_DESCR);\n",
    "df_location = rename(locationDF, :ID => :LOCATION_ID, :CLASSIFICATION => :LOCATION_CLASSIFICATION,\n",
    "    :CATEGORY => :LOCATION_CATEGORY, :DESCR => :LOCATION_DESCR);\n",
    "\n",
    "# join Ledger accounts chartfield with accounts chartfield dataframe to pull all accounts fields\n",
    "# join Ledger dept chartfield with dept chartfield dataframe to pull all dept fields\n",
    "# join Ledger location chartfield with location chartfield dataframe to pull all location fields\n",
    "df_ledger = innerjoin(\n",
    "                innerjoin(\n",
    "                    innerjoin(ledgerDF, df_accounts, on = [:ACCOUNT => :ACCOUNTS_ID], makeunique=true),\n",
    "                    df_dept, on = [:DEPT => :DEPT_ID], makeunique=true), df_location,\n",
    "                on = [:LOCATION => :LOCATION_ID], makeunique=true);\n",
    "\n",
    "# note, how ledger DF has 28 columns now (inclusive of all chartfields join)\n",
    "size(df_accounts),size(df_dept),size(df_location), size(ledgerDF), size(df_ledger)\n",
    "\n",
    "function periodToQtr(x)\n",
    "    if x ∈ 1:3\n",
    "        return 1\n",
    "    elseif x ∈ 4:6\n",
    "        return 2\n",
    "    elseif x ∈ 7:9\n",
    "        return 3\n",
    "    else return 4\n",
    "    end\n",
    "end\n",
    "\n",
    "# now we will use this function to transform a new column\n",
    "transform!(df_ledger, :PERIOD => ByRow(periodToQtr) => :QTR)\n",
    "\n",
    "# let's create one more generic function, which converts a number to USD currency\n",
    "function numToCurrency(x)\n",
    "        return string(\"USD \",round(x/10^6; digits = 2), \" million\")\n",
    "end\n",
    "\n",
    "transform!(df_ledger, :POSTED_TOTAL => ByRow(numToCurrency) => :TOTAL)\n",
    "df_ledger[1:5,[\"POSTED_TOTAL\",\"TOTAL\"]]\n",
    "\"df_ledger_size after transformation is: \", size(df_ledger)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "6c4e26abee5642148a2f25c2e4c7dda1",
   "lastKernelId": "ff6555df-dff2-4490-9640-d7a8135f90b6"
  },
  "kernelspec": {
   "display_name": "Julia (4 threads) 1.7.0",
   "language": "julia",
   "name": "julia-(4-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
