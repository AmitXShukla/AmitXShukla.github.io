{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything you need to know about Julia DataFrames to support ERP Data Science Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:** Most of Enterprise ERP providers like SAP, Oracle, Microsoft build HCM, Finance, Supply Chain, CRM like systems, which store data in highly structured RDBMS tables.\n",
    "Recent advancements in ERP systems also support authoring non-structured data like digital invoices, receipt or hand-held OCR readers.\n",
    "\n",
    "All of these ERP systems are great OLTP systems, but depend on Analytic systems for creating dashboards, ad-hoc analysis, operational reporting or live predictive analytics.\n",
    "\n",
    "Further, ERP systems depend on ELT/ELT or 3rd party tools for data mining, analysis and visualizations.\n",
    "\n",
    "While data engineers use Java, Scala, SPARK based big data solutions to move data, they depend on 3rd party BI Reporting tools for creating dashboards, use Data Mining tools for data cleansing and AI Languages for advance predictive analytics.\n",
    "\n",
    "When I started learning more about Julia Language, I thought of using Julia Language to solve ERP Analytics multiple languages problem.\n",
    "Why not just use Julia Language to move, clean massive data set as Big data reporting solution, as Julia support multi-threading, distributing parallel computing.\n",
    "Julia language and associated packages has first class support for large arrays, which can be used for data analysis.\n",
    "\n",
    "and Julia has great visualization packages to publish interactive dashboards, live data reporting.\n",
    "\n",
    "best of all, Julia is great in numerical computing, advance data science machine learning.\n",
    "\n",
    "This blog, I am sharing my notes specific to perform typical ERP data analysis using Julia Language.\n",
    "\n",
    "**Target Audience:** This notebook, is meant for ERP consultants, IT Developers, Finance, Supply chain, HR & CRM managers, executive leaders or anyone curious to implement data science concepts in ERP space.\n",
    "\n",
    "+ **Author:** Amit Shukla\n",
    "+ **Contact:** info@elishconsulting.com\n",
    "\n",
    "-----\n",
    "\n",
    "# - About ERP Systems, General Ledger & Supply chain\n",
    "A typical ERP system consists of many modules based on business domain, functions and operations.\n",
    "GL is core of Finance and Supply chain domains and Buy to Pay, Order to Cash deal with different aspects of business operations in an Organization.\n",
    "Many organization, use ERPs in different ways and may chose to implement all or some of the modules.\n",
    "You can find examples of module specific business operations/processes diagram here.\n",
    "- [General Ledger process flow](https://github.com/AmitXShukla/AmitXShukla.github.io/raw/master/blogs/PlutoCon/gl.png)\n",
    "- [Account Payable process flow](https://github.com/AmitXShukla/AmitXShukla.github.io/raw/master/blogs/PlutoCon/ap.png)\n",
    "- [Tax Analytics](https://github.com/AmitXShukla/AmitXShukla.github.io/raw/master/blogs/PlutoCon/tax.png)\n",
    "- [Sample GL ERD - Entity Relaton Diagram](https://github.com/AmitXShukla/AmitXShukla.github.io/raw/master/blogs/PlutoCon/gl_erd.png)\n",
    "\n",
    "A typical ERP modules list looks like below diagram.\n",
    "\n",
    "![ERP Modules](https://github.com/AmitXShukla/AmitXShukla.github.io/raw/master/blogs/PlutoCon/ERP_modules.png)\n",
    "\n",
    "A typical ERP business process flow looks like below diagram.\n",
    "\n",
    "![ERP Processes](https://github.com/AmitXShukla/P2P.ai/blob/main/docs/assets/images/ERD_logical.png?raw=true)\n",
    "\n",
    "A typical GL Balance sheet, Cash-flow or Income Statement looks like this \n",
    "\n",
    "[click here](https://s2.q4cdn.com/470004039/files/doc_financials/2020/q4/FY20_Q4_Consolidated_Financial_Statements.pdf)\n",
    "\n",
    "In this notebook, I will do my best to cite examples from real world data like above mentioned GL Financial statement.\n",
    "\n",
    "---\n",
    "\n",
    "# start with Julia \n",
    "It literally takes < 1 min to install Julia environments on almost any machine.\n",
    "\n",
    "Here is [link to my tutorial](https://medium.com/me/stats/post/823d84f2cb28), which discuss Julia installation on different machines (including remote and mobile tablets).\n",
    "\n",
    "\n",
    "## adding Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
      " \u001b[90m [324d7699] \u001b[39mCategoricalArrays v0.10.5\n",
      " \u001b[90m [a93c6f00] \u001b[39mDataFrames v1.3.2\n",
      " \u001b[90m [7073ff75] \u001b[39mIJulia v1.23.2\n",
      " \u001b[90m [c3e4b0f8] \u001b[39mPluto v0.18.4\n",
      " \u001b[90m [2dfb63ee] \u001b[39mPooledArrays v1.4.0\n",
      " \u001b[90m [ade2ca70] \u001b[39mDates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Dates\")\n",
    "using DataFrames, Dates\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*rest of this blog, I will assume, you have added all packages and imported in current namespace/notebook scope.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.46708904491315945"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat([\"AMIT\",\"SHUKLA\"], inner=5) # repeat list/string number of times\n",
    "fill(\"34\", 4) # repeat list/string number of times\n",
    "range(1.0, stop=9.0, length=100) # generate n number of equal values between start and stop values\n",
    "11000:1000:45000 # genarate a range of # from start to finish with set intervals\n",
    "collect(1:4) # collect funtion collect all values in list\n",
    "rand([1,2,3,4]) # random value from a list of values\n",
    "rand(11000:1000:45000) # random value from a list of values\n",
    "randn() # random # from a list of float values (+ or -)\n",
    "\n",
    "# more helper string functions - replace etc... \n",
    "# fill these in from Pluto notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create DataFrame\n",
    "\n",
    "Chart of accounts (organized hierarchy of account groups in tree form), Location/Department or Product based hierarchy allows businesses to group and report organization activities based on business processes.\n",
    "\n",
    "These hierarchical grouping help capture monetary and statistical values of organization in finance statements.\n",
    "\n",
    "---\n",
    "\n",
    "To create Finance Data model and \n",
    "[Ledger Cash-flow or Balance Sheet like statements](https://s2.q4cdn.com/470004039/files/doc_financials/2020/q4/FY20_Q4_Consolidated_Financial_Statements.pdf),\n",
    "We need associated dimensions (chartfields like chart of accounts).\n",
    "\n",
    "We will discuss how to load actual data from CSV or RDBMS later. We will also learn how to group and create chartfield hierarchies later.\n",
    "\n",
    "But for now, first Let's start with creating fake ACCOUNT, department and location chartfields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Accounts DIM size is: \"(35, 7)\"Accounts Dim sample: \""
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nothing, nothing, nothing, \u001b[1m7×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m AS_OF_DATE \u001b[0m\u001b[1m ID    \u001b[0m\u001b[1m CLASSIFICATION         \u001b[0m\u001b[1m CATEGORY     \u001b[0m\u001b[1m STATUS \u001b[0m\u001b[1m DESCR \u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Date       \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m String                 \u001b[0m\u001b[90m String       \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 1900-01-01  11000  OPERATING_EXPENSES      Travel        A       operat ⋯\n",
       "   2 │ 1900-01-01  16000  NON-OPERATING_EXPENSES  Facility      A       non-op\n",
       "   3 │ 1900-01-01  21000  ASSETS                  Depreciation  A       assets\n",
       "   4 │ 1900-01-01  26000  LIABILITIES             Receipt       A       liabil\n",
       "   5 │ 1900-01-01  31000  NET_WORTH               Cash          A       net-wo ⋯\n",
       "   6 │ 1900-01-01  36000  STATISTICS              FTE           A       stats\n",
       "   7 │ 1900-01-01  41000  REVENUE                 Sales         A       revenu\n",
       "\u001b[36m                                                               2 columns omitted\u001b[0m)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy data\n",
    "accounts = DataFrame(AS_OF_DATE=Date(\"1900-01-01\", dateformat\"y-m-d\"), \n",
    "    ID = 11000:1000:45000,\n",
    "    CLASSIFICATION=repeat([\n",
    "        \"OPERATING_EXPENSES\",\"NON-OPERATING_EXPENSES\", \"ASSETS\",\"LIABILITIES\",\"NET_WORTH\",\"STATISTICS\",\"REVENUE\"\n",
    "                ], inner=5),\n",
    "    CATEGORY=[\n",
    "        \"Travel\",\"Payroll\",\"non-Payroll\",\"Allowance\",\"Cash\",\n",
    "        \"Facility\",\"Supply\",\"Services\",\"Investment\",\"Misc.\",\n",
    "        \"Depreciation\",\"Gain\",\"Service\",\"Retired\",\"Fault.\",\n",
    "        \"Receipt\",\"Accrual\",\"Return\",\"Credit\",\"ROI\",\n",
    "        \"Cash\",\"Funds\",\"Invest\",\"Transfer\",\"Roll-over\",\n",
    "        \"FTE\",\"Members\",\"Non_Members\",\"Temp\",\"Contractors\",\n",
    "        \"Sales\",\"Merchant\",\"Service\",\"Consulting\",\"Subscriptions\"],\n",
    "    STATUS=\"A\",\n",
    "    DESCR=repeat([\n",
    "    \"operating expenses\",\"non-operating expenses\",\"assets\",\"liability\",\"net-worth\",\"stats\",\"revenue\"], inner=5),\n",
    "    ACCOUNT_TYPE=repeat([\"E\",\"E\",\"A\",\"L\",\"N\",\"S\",\"R\"],inner=5));\n",
    "\n",
    "show(\"Accounts DIM size is: \"), show(size(accounts)), show(\"Accounts Dim sample: \"), accounts[collect(1:5:35),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is lot to unpack here in above Julia code and lot is wrong (not best practice for sure).\n",
    "\n",
    "First, **what is a dataframe anyway**, think of Julia DataFrame as tabular representation of data arranged in rows and columns. Unlike SQL, you should get into habit of reading and writing one column at a time (not because of reason, you can't read/write rows). Each column is an Array or a list of values, referred as vector.\n",
    "\n",
    "Above Julia code creates accounts dataframe with columns name as AS_OF_DATE, DESCR, CATEGORY, ACCOUNT_TYPE, CLASSIFICATION, STATUS.\n",
    "\n",
    "There are 35 rows, with same AS_OF_DATE, IDs starting from 11000-45000 in 1000 incremental values, all with STATUS = A (Active), 7 distinct Descriptions and account types (E=Expense, L=Liability, A= Assets, N=Net worth, S=Stats, R=Revenue) repeating 5 times per category.\n",
    "\n",
    "For 35 rows, it's fine to store data like this, but now is a good time to learn about Categorical and Pooled Arrays, in case when dataframe has millions of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
      " \u001b[90m [324d7699] \u001b[39mCategoricalArrays v0.10.5\n",
      " \u001b[90m [a93c6f00] \u001b[39mDataFrames v1.3.2\n",
      " \u001b[90m [7073ff75] \u001b[39mIJulia v1.23.2\n",
      " \u001b[90m [c3e4b0f8] \u001b[39mPluto v0.18.4\n",
      " \u001b[90m [2dfb63ee] \u001b[39mPooledArrays v1.4.0\n",
      " \u001b[90m [ade2ca70] \u001b[39mDates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"CategoricalArrays\")\n",
    "Pkg.add(\"PooledArrays\")\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>12 rows × 2 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>Descr</th><th>Value</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>CLASSIFICATION...ARR...</td><td>3500</td></tr><tr><th>2</th><td>CAT...ARR...</td><td>3500</td></tr><tr><th>3</th><td>CAT...ARR..COMPRESS.</td><td>3500</td></tr><tr><th>4</th><td>POOL...ARR...</td><td>3500</td></tr><tr><th>5</th><td>POOL...ARR..COMPRESS.</td><td>3500</td></tr><tr><th>6</th><td>CAT...LEVELs...</td><td>7</td></tr><tr><th>7</th><td>POOL...LEVELs...</td><td>7</td></tr><tr><th>8</th><td>CLASSIFICATION...MEMSIZE</td><td>28179</td></tr><tr><th>9</th><td>CAT...ARR...MEMSIZE</td><td>14739</td></tr><tr><th>10</th><td>POOL...ARR...MEMSIZE</td><td>14739</td></tr><tr><th>11</th><td>CAT...ARR..COMPRESS...MEMSIZE</td><td>4191</td></tr><tr><th>12</th><td>POOL...ARR..COMPRESS...MEMSIZE</td><td>4191</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& Descr & Value\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & CLASSIFICATION...ARR... & 3500 \\\\\n",
       "\t2 & CAT...ARR... & 3500 \\\\\n",
       "\t3 & CAT...ARR..COMPRESS. & 3500 \\\\\n",
       "\t4 & POOL...ARR... & 3500 \\\\\n",
       "\t5 & POOL...ARR..COMPRESS. & 3500 \\\\\n",
       "\t6 & CAT...LEVELs... & 7 \\\\\n",
       "\t7 & POOL...LEVELs... & 7 \\\\\n",
       "\t8 & CLASSIFICATION...MEMSIZE & 28179 \\\\\n",
       "\t9 & CAT...ARR...MEMSIZE & 14739 \\\\\n",
       "\t10 & POOL...ARR...MEMSIZE & 14739 \\\\\n",
       "\t11 & CAT...ARR..COMPRESS...MEMSIZE & 4191 \\\\\n",
       "\t12 & POOL...ARR..COMPRESS...MEMSIZE & 4191 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m12×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Descr                          \u001b[0m\u001b[1m Value \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String                         \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "─────┼───────────────────────────────────────\n",
       "   1 │ CLASSIFICATION...ARR...          3500\n",
       "   2 │ CAT...ARR...                     3500\n",
       "   3 │ CAT...ARR..COMPRESS.             3500\n",
       "   4 │ POOL...ARR...                    3500\n",
       "   5 │ POOL...ARR..COMPRESS.            3500\n",
       "   6 │ CAT...LEVELs...                     7\n",
       "   7 │ POOL...LEVELs...                    7\n",
       "   8 │ CLASSIFICATION...MEMSIZE        28179\n",
       "   9 │ CAT...ARR...MEMSIZE             14739\n",
       "  10 │ POOL...ARR...MEMSIZE            14739\n",
       "  11 │ CAT...ARR..COMPRESS...MEMSIZE    4191\n",
       "  12 │ POOL...ARR..COMPRESS...MEMSIZE   4191"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here CLASSIFICATION column vector stores 3500 distinct values in an array\n",
    "CLASSIFICATION=repeat([\"OPERATING_EXPENSES\",\"NON-OPERATING_EXPENSES\", \"ASSETS\",\"LIABILITIES\",\"NET_WORTH\",\"STATISTICS\",\"REVENUE\"\n",
    "                ], inner=500)\n",
    "\n",
    "using CategoricalArrays\n",
    "cl = categorical(CLASSIFICATION)\n",
    "levels(cl)\n",
    "\n",
    "using PooledArrays\n",
    "pl = categorical(CLASSIFICATION)\n",
    "levels(pl)\n",
    "\n",
    "# show values in tabular format\n",
    "df = DataFrame(Dict(\"Descr\" => \"CLASSIFICATION...ARR...\", \"Value\" => size(CLASSIFICATION)[1]))\n",
    "push!(df,(\"CAT...ARR...\",size(cl)[1]))\n",
    "push!(df,(\"CAT...ARR..COMPRESS.\",size(compress(cl))[1]))\n",
    "push!(df,(\"POOL...ARR...\",size(pl)[1]))\n",
    "push!(df,(\"POOL...ARR..COMPRESS.\",size(compress(pl))[1]))\n",
    "push!(df,(\"CAT...LEVELs...\",size(levels(cl))[1]))\n",
    "push!(df,(\"POOL...LEVELs...\",size(levels(pl))[1]))\n",
    "push!(df,(\"CLASSIFICATION...MEMSIZE\", Base.summarysize(CLASSIFICATION)))\n",
    "push!(df,(\"CAT...ARR...MEMSIZE\", Base.summarysize(cl)))\n",
    "push!(df,(\"POOL...ARR...MEMSIZE\", Base.summarysize(pl)))\n",
    "push!(df,(\"CAT...ARR..COMPRESS...MEMSIZE\", Base.summarysize(compress(cl))))\n",
    "push!(df,(\"POOL...ARR..COMPRESS...MEMSIZE\", Base.summarysize(compress(pl))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical and Pooled Arrays** as name suggests, are data structure to store voluminous data efficiently,specially when a column in a data frame has small number of distinct values (aka levels), repeated across entire column vector.\n",
    "\n",
    "as an example, Finance Ledger may have millions of transactions and every row has one of these seven type of accounts. It's not recommended to store repeating value of entire string in every row. Instead, using a Categorical or PooledArray data type, memory/data size can be significantly reduced with out losing any data quality. (size(..) stays same for original, Categorical and PooledArray data type.\n",
    "\n",
    "as you can see in above example, size of categorical / pooled array data type matches with original column vector but significantly reduces size/memory of data. (Base.summarysize(...)) is reduced 50% and is further reduced by 85% if used with compress(...))\n",
    "\n",
    "Using Categorical Array type over PooledArray is recommended when there are fewer unique values, user need meaningful ordering and grouping. On the other hand, PoolArray is preferred when small memory usage is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ways of creating dataframe\n",
    "\n",
    "There are different ways of creating dataframe, and it all depends on how user want to see data, which is almost always tabular anyway.\n",
    "\n",
    "There are few things to keep in mind when working DataFrames.\n",
    "\n",
    "- Think in terms of columns, and pay attention to column datatypes. for example, as mentioned earlier, using Categorical or PooledArray can significantly improve data analysis performance and save on memory\n",
    "- Think, how do you want to filter dataset, and in that case, row index become very important.\n",
    "- Pay attention to column names (column names with spaces, or special characters, can cause inconvenience). Julia has class support for variable names, which means it can store any type of literal string and not break. But one should follow standard guidelines for naming conventions.\n",
    "- Pay attention to read dataframe columns efficiently, reading/mutating original version can harm data quality and analysis but unnecessary making copies of data add clutter to your temp space.\n",
    "- Often DataFrames is good enough to support any query and transformations, but just in case, if you need, there are more data query frameworks like DataFramesMeta.jl & Query.jl to support advance use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating data frame from \n",
    "this is a tuple\n",
    "this is a named tuple\n",
    "this is a vector\n",
    "this is a categorical vector\n",
    "\n",
    "## creating data frame from CSV, JSON, ODBC/ORM, XML\n",
    "DataFrame(a=1:2, b=[1.0, missing],\n",
    "                 c=categorical('a':'b'), d=[1//2, missing])\n",
    "from tuple\n",
    "series\n",
    "dataframe\n",
    "dict\n",
    "namedtuple\n",
    "csv\n",
    "xls\n",
    "json\n",
    "xml\n",
    "sql\n",
    "column name with space\n",
    "tuple\n",
    "named tuple\n",
    "dicts\n",
    "\n",
    "normal/guassian distribution\n",
    "\n",
    "## type systems\n",
    "ledger\n",
    "subledger\n",
    "accounting\n",
    "chartfields\n",
    "\n",
    "category\n",
    "typeof\n",
    "subtypes\n",
    "supertype\n",
    "eltypes\n",
    "\n",
    "\n",
    "#### show functions\n",
    "first\n",
    "last\n",
    "show\n",
    "eachcol\n",
    "nrow\n",
    "ncols\n",
    "names\n",
    "propertynames\n",
    "describe\n",
    "eltype\n",
    "\n",
    "## transformation\n",
    "\n",
    "unique rows\n",
    "group by\n",
    "order by\n",
    "sort\n",
    "\n",
    "\n",
    "mapscols\n",
    "broadcasting\n",
    "ncols\n",
    "cols\n",
    "regesx\n",
    "match\n",
    "view\n",
    "\n",
    "#group by\n",
    "\n",
    "# Visualization\n",
    "\n",
    "# build interactive visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/ubuntu/amit/WIP/AmitXShukla.github.io/blogs/julia\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello Friends,\n",
    "In this video, we will discuss everything one need to know about Julia Data Frames to perform a detail ERP Data analyis.\n",
    "\n",
    "In case if you are not familiar with Julia Language, it's one of newer langauge for Data Science, you can compare this with R and Python. However, it's a newer language, which runs like C and walks like Python.\n",
    "\n",
    "I'm not going to discuss, R vs Python vs Julia, I think, each language has Pros and Cons. Please don't waste your time on pointless powerpoint comparisons, specially when it's easier to just pick these languages and start coding, and you will sooner or later, once you get a hang of programming language, there comes a time, you will know, which language meets your need.\n",
    "\n",
    "In this blog, we will discuss following topics.\n",
    "\n",
    "1. about ERP data analysiswhat are \n",
    "2. why Julia Language\n",
    "3. Julia & package Installation\n",
    "4. using Julia Data Frames for data analysis\n",
    "5. Data Visualization\n",
    "6. other packages like online stats, ODBC, JuliaDB\n",
    "7. Data Cleansing, Wrangling, Masking & Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (4 threads) 1.7.0",
   "language": "julia",
   "name": "julia-(4-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
